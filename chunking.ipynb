{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "946ebd13-14eb-404b-8ab1-82e0d1a87888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader('resume_narrative.txt')\n",
    "data=loader.load()\n",
    "data[0].metadata\n",
    "\n",
    "text = data[0].page_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1edfc0b3-4fc6-47e9-a012-7383985efccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'resume_narrative.txt'}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a33608a0-b009-4e97-8da7-c58726fc016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators = ['\\n\\n', '\\n', ' '],\n",
    "    chunk_size = 200,\n",
    "    chunk_overlap = 50\n",
    ")\n",
    "chunks = r_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a90eb5e2-db1d-409e-8558-1f4084c1dc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Personal Information',\n",
       " 'Santosh Kumar is a seasoned Software Engineer based in Bangalore, India, with a deep-seated passion for artificial intelligence and machine learning. With a robust portfolio that includes significant',\n",
       " 'With a robust portfolio that includes significant contributions to various tech fields and a remarkable academic background, Santosh has established himself as a versatile and fast-learning',\n",
       " 'himself as a versatile and fast-learning professional. His journey is marked by a persistent drive to bridge the gap between innovative research and practical applications, a goal he pursues through',\n",
       " 'practical applications, a goal he pursues through a variety of collaborative projects and independent ventures.',\n",
       " 'Santosh holds a Bachelor of Technology degree in Computer Science and Engineering from Dr. B. C. Roy Engineering College, where he graduated with a CGPA of 7.92. His academic journey was not only a',\n",
       " 'CGPA of 7.92. His academic journey was not only a period of acquiring theoretical knowledge but also a time of engaging in practical projects and internships that laid a solid foundation for his',\n",
       " 'internships that laid a solid foundation for his career. He is also a published researcher, with his work on Image Steganography being recognized at an IEEE conference.',\n",
       " 'Santosh is a prolific learner, constantly acquiring new skills to stay at the forefront of technological advancements. His technical toolkit includes TensorFlow, OpenCV, React.js, Node.js, and',\n",
       " 'TensorFlow, OpenCV, React.js, Node.js, and various other full-stack technologies. He is also well-versed in Sanskrit scriptures, which he believes hold significant potential for advancing AI and NLP',\n",
       " 'significant potential for advancing AI and NLP to achieve telegraphic precision and lossless semantics. Santosh is always on the lookout for opportunities to collaborate and innovate, aiming to shape',\n",
       " 'to collaborate and innovate, aiming to shape the digital future and contribute to the global tech community.',\n",
       " 'Professional Experience\\nJunior Software Engineer at Pacecom Technologies Pvt Ltd (05/2023 - Present)',\n",
       " 'Santosh currently serves as a Junior Software Engineer at Pacecom Technologies Pvt Ltd in Bangalore, India. In this role, he has led several image processing tasks on drone-captured imagery to',\n",
       " 'processing tasks on drone-captured imagery to enhance state border security, achieving a 60% improvement in accuracy using machine learning and computer vision techniques. One of his notable projects',\n",
       " 'vision techniques. One of his notable projects involved developing a question-answering system using NLP and Hugging Face for chunking and vectorization, integrating the Milvus database for storing',\n",
       " 'integrating the Milvus database for storing data, and utilizing Langchain for query expansion. This system significantly enhanced analytics reports for drone surveillance data.',\n",
       " 'He has also developed three full-stack applications using React, Node.js, and MongoDB, which were hosted on AWS, improving user experience and functionality. Additionally, Santosh trained AI/ML',\n",
       " 'Additionally, Santosh trained AI/ML models on extensive drone-captured farmland imagery to accurately segregate individual plots, identify crop types, and calculate projected yields with 80%',\n",
       " 'types, and calculate projected yields with 80% accuracy. His efforts have optimized agricultural planning and decision-making. Beyond technical contributions, Santosh has played a crucial role in',\n",
       " \"Santosh has played a crucial role in mentoring interns and collaborating with cross-functional teams to meet the Karnataka State Government Forest Department's requirements.\",\n",
       " 'Freelance Web Developer (03/2020 - 01/2023)',\n",
       " 'During the COVID-19 lockdown, Santosh ventured into freelancing, broadening his expertise in web development. He focused on delivering tailored web solutions using Laravel, React, and Node.js.',\n",
       " 'web solutions using Laravel, React, and Node.js. Notably, he developed a web application for NGOs involved in food and relief distribution, allowing users to register and track the distribution',\n",
       " 'users to register and track the distribution process. This experience honed his technical skills and improved his ability to communicate effectively with clients and manage projects independently.',\n",
       " 'Researcher at College R&D for IEEE (02/2018 - 01/2020)',\n",
       " 'As a researcher in the College R&D for IEEE, Santosh developed an Image Steganography algorithm that enhanced encryption and decryption efficacy. This work was presented at an IEEE conference,',\n",
       " 'This work was presented at an IEEE conference, showcasing significant advancements in the field. He also assisted in creating mathematical models for a PhD thesis, focusing on calculating fairness',\n",
       " 'a PhD thesis, focusing on calculating fairness indices and detecting communities in complex networks. This role involved extensive mathematical analysis and critical evaluation of research',\n",
       " 'analysis and critical evaluation of research literature, contributing to significant advancements in the field.',\n",
       " 'Projects\\nPortfolio Web Application with LLM NLP Chatbot (06/2024 - 07/2024)',\n",
       " 'Santosh developed a portfolio web application using the MERN stack, integrating NLP technologies, including LLM API and Langchain, to create a chatbot capable of answering queries about his projects',\n",
       " 'capable of answering queries about his projects and work experience. This application allows HR and recruiters to interactively explore his resume, enhancing user engagement and usability.',\n",
       " 'Data Science Capstone Project (08/2022 - 09/2022)',\n",
       " 'In this project, Santosh applied various data science techniques to assess the landing accuracy of rockets. The project involved data visualization, machine learning, and extensive use of Python',\n",
       " 'machine learning, and extensive use of Python tools to handle large datasets, perform data cleaning, and develop predictive models.',\n",
       " 'Fisherman Game - Python Project (09/2022)',\n",
       " 'Santosh created an interactive game using the Pygame package in Python. This project involved designing game mechanics, developing graphics, and ensuring smooth gameplay, combining his programming',\n",
       " 'smooth gameplay, combining his programming skills with creativity.',\n",
       " 'Publications\\nA Novel Approach to Hide Text Data in Colour Image (08/2018)',\n",
       " 'In this IEEE-published paper, Santosh presented a novel Image Steganography algorithm that overcomes limitations and performance bottlenecks of existing algorithms. The research demonstrated',\n",
       " 'of existing algorithms. The research demonstrated significant improvements in encryption and decryption processes, receiving positive feedback at an IEEE conference.',\n",
       " 'Education',\n",
       " 'Santosh completed his Bachelor of Technology in Computer Science and Engineering at Dr. B. C. Roy Engineering College, achieving a CGPA of 7.92. His education provided a comprehensive understanding',\n",
       " 'education provided a comprehensive understanding of programming, data structures, algorithms, computer networks, and software engineering.',\n",
       " 'Certificates',\n",
       " 'Santosh has earned several certifications, including the IBM Data Science Professional Certificate, Google\\'s \"The Bits and Bytes of Computer Networking,\" Oracle PL/SQL, and Stanford University\\'s',\n",
       " 'Oracle PL/SQL, and Stanford University\\'s \"Introduction to Logic.\" These certifications reflect his continuous learning and proficiency in various technical domains.']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "95fd794a-0662-4b87-a421-203a72615f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to generate embeddings\n",
    "def generate_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.detach().numpy()\n",
    "\n",
    "# Generate embeddings for chunks\n",
    "embeddings = [generate_embedding(chunk) for chunk in chunks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e481b91c-ab9e-47d4-b9e6-8abba3a68d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d4b5262f-0373-4e87-a2cd-c634109cc91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1ec9fcd3-801f-45b1-acc0-7734cff64810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 384)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[47].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9ffc4ce4-b5fb-4715-a692-313114e760a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, CollectionSchema, FieldSchema, DataType, Collection, utility\n",
    "\n",
    "# Connect to Milvus\n",
    "# connections.connect(alias=\"default\", host=\"127.0.0.1\", port=\"19530\")\n",
    "\n",
    "# Define fields for your collection\n",
    "fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=384),  # Replace with your actual embedding dimension\n",
    "    FieldSchema(name=\"text_chunk\", dtype=DataType.VARCHAR, max_length=500)  # Optionally store the text chunk\n",
    "]\n",
    "\n",
    "# Create the schema\n",
    "schema = CollectionSchema(fields, \"Schema for storing text embeddings\")\n",
    "\n",
    "# Check if collection exists and drop if it does\n",
    "if utility.has_collection(\"resume_collection\"):\n",
    "    utility.drop_collection(\"resume_collection\")\n",
    "\n",
    "# Create the collection\n",
    "collection = Collection(name=\"resume_collection\", schema=schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f1ca14b0-82eb-4919-a40b-446f3c313680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(insert count: 48, delete count: 0, upsert count: 0, timestamp: 451369721061703686, success count: 48, err count: 0, cost: 0)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten the embeddings to match the expected input format\n",
    "flattened_embeddings = [embedding.flatten() for embedding in embeddings]\n",
    "\n",
    "# Prepare data for insertion\n",
    "data = [\n",
    "    flattened_embeddings,  # Your actual embeddings\n",
    "    chunks  # Text chunks\n",
    "]\n",
    "\n",
    "# Insert data into Milvus\n",
    "collection.insert(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "956df8c6-5ee0-4397-a1b8-cfa153b17974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(code=0, message=)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an index for the embeddings\n",
    "index_params = {\n",
    "    \"index_type\": \"IVF_FLAT\",\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {\"nlist\": 128}\n",
    "}\n",
    "\n",
    "collection.create_index(field_name=\"embedding\", index_params=index_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0b7d5975-3e92-4014-9e2c-338707b4b43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flush to ensure data is written\n",
    "collection.flush()\n",
    "\n",
    "# Load collection for querying\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a042b5-c15a-449a-822e-9d459f4bd082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5a497d11-3cac-468d-a177-7f49ff474974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to generate embeddings\n",
    "def generate_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.detach().numpy().flatten()\n",
    "\n",
    "# Example query text\n",
    "query_text = \"where does Santosh Work?\"\n",
    "\n",
    "# Generate embedding for the query text\n",
    "query_embedding = generate_embedding(query_text).tolist()\n",
    "\n",
    "# Perform a similarity search\n",
    "search_params = {\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {\"nprobe\": 10},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9ad038cc-09da-43cd-94a9-097c1ee9a325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "ID: 451358733081252905\n",
      "Text Chunk: Santosh has played a crucial role in mentoring interns and collaborating with cross-functional teams to meet the Karnataka State Government Forest Department's requirements.\n",
      "==================================================\n",
      "ID: 451358733081252886\n",
      "Text Chunk: Santosh Kumar is a seasoned Software Engineer based in Bangalore, India, with a deep-seated passion for artificial intelligence and machine learning. With a robust portfolio that includes significant\n",
      "==================================================\n",
      "ID: 451358733081252893\n",
      "Text Chunk: Santosh is a prolific learner, constantly acquiring new skills to stay at the forefront of technological advancements. His technical toolkit includes TensorFlow, OpenCV, React.js, Node.js, and\n",
      "==================================================\n",
      "ID: 451358733081252898\n",
      "Text Chunk: Santosh currently serves as a Junior Software Engineer at Pacecom Technologies Pvt Ltd in Bangalore, India. In this role, he has led several image processing tasks on drone-captured imagery to\n",
      "==================================================\n",
      "ID: 451358733081252907\n",
      "Text Chunk: During the COVID-19 lockdown, Santosh ventured into freelancing, broadening his expertise in web development. He focused on delivering tailored web solutions using Laravel, React, and Node.js.\n",
      "==================================================\n",
      "ID: 451358733081252887\n",
      "Text Chunk: With a robust portfolio that includes significant contributions to various tech fields and a remarkable academic background, Santosh has established himself as a versatile and fast-learning\n",
      "==================================================\n",
      "ID: 451358733081252904\n",
      "Text Chunk: types, and calculate projected yields with 80% accuracy. His efforts have optimized agricultural planning and decision-making. Beyond technical contributions, Santosh has played a crucial role in\n",
      "==================================================\n",
      "ID: 451358733081252890\n",
      "Text Chunk: Santosh holds a Bachelor of Technology degree in Computer Science and Engineering from Dr. B. C. Roy Engineering College, where he graduated with a CGPA of 7.92. His academic journey was not only a\n",
      "==================================================\n",
      "ID: 451358733081252928\n",
      "Text Chunk: Santosh completed his Bachelor of Technology in Computer Science and Engineering at Dr. B. C. Roy Engineering College, achieving a CGPA of 7.92. His education provided a comprehensive understanding\n",
      "==================================================\n",
      "ID: 451358733081252895\n",
      "Text Chunk: significant potential for advancing AI and NLP to achieve telegraphic precision and lossless semantics. Santosh is always on the lookout for opportunities to collaborate and innovate, aiming to shape\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "results = collection.search(\n",
    "    data=[query_embedding],  # List of query embeddings\n",
    "    anns_field=\"embedding\",  # Field name of the embeddings\n",
    "    param=search_params,\n",
    "    limit=10,  # Number of similar entries to retrieve\n",
    "    expr=None,  # Optional filter expression\n",
    "    output_fields=[\"id\", \"embedding\", \"text_chunk\"]\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(len(results[0]))\n",
    "for result in results[0]:  # results[0] because results is a list of lists\n",
    "    print(f\"ID: {result.id}\")\n",
    "    # print(f\"Embedding: {result.embedding}\")\n",
    "    print(f\"Text Chunk: {result.text_chunk}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a8f149c3-82c7-4b74-a1e4-55030e210f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query text\n",
    "query_text = \"What works has he done?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "dd7c1e00-75ef-4ee1-9078-59b6ba360a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Text Chunks for Context:\n",
      "himself as a versatile and fast-learning professional. His journey is marked by a persistent drive to bridge the gap between innovative research and practical applications, a goal he pursues through\n",
      "\n",
      "internships that laid a solid foundation for his career. He is also a published researcher, with his work on Image Steganography being recognized at an IEEE conference.\n",
      "\n",
      "practical applications, a goal he pursues through a variety of collaborative projects and independent ventures.\n",
      "\n",
      "CGPA of 7.92. His academic journey was not only a period of acquiring theoretical knowledge but also a time of engaging in practical projects and internships that laid a solid foundation for his\n",
      "\n",
      "capable of answering queries about his projects and work experience. This application allows HR and recruiters to interactively explore his resume, enhancing user engagement and usability.\n",
      "\n",
      "With a robust portfolio that includes significant contributions to various tech fields and a remarkable academic background, Santosh has established himself as a versatile and fast-learning\n",
      "\n",
      "Santosh is a prolific learner, constantly acquiring new skills to stay at the forefront of technological advancements. His technical toolkit includes TensorFlow, OpenCV, React.js, Node.js, and\n",
      "\n",
      "TensorFlow, OpenCV, React.js, Node.js, and various other full-stack technologies. He is also well-versed in Sanskrit scriptures, which he believes hold significant potential for advancing AI and NLP\n",
      "\n",
      "During the COVID-19 lockdown, Santosh ventured into freelancing, broadening his expertise in web development. He focused on delivering tailored web solutions using Laravel, React, and Node.js.\n",
      "\n",
      "He has also developed three full-stack applications using React, Node.js, and MongoDB, which were hosted on AWS, improving user experience and functionality. Additionally, Santosh trained AI/ML\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import connections, Collection\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Connect to Milvus\n",
    "# connections.connect(alias=\"default\", host=\"127.0.0.1\", port=\"19530\")\n",
    "\n",
    "# Load the collection\n",
    "collection = Collection(name=\"resume_collection\")\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to generate embeddings\n",
    "def generate_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.detach().numpy().flatten()\n",
    "\n",
    "# Example query text\n",
    "# query_text = \"Where do Santosh Work?\"\n",
    "\n",
    "# Generate embedding for the query text\n",
    "query_embedding = generate_embedding(query_text).tolist()\n",
    "\n",
    "# Perform a similarity search\n",
    "search_params = {\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {\"nprobe\": 10},\n",
    "}\n",
    "\n",
    "results = collection.search(\n",
    "    data=[query_embedding],  # List of query embeddings\n",
    "    anns_field=\"embedding\",  # Field name of the embeddings\n",
    "    param=search_params,\n",
    "    limit=10,  # Number of similar entries to retrieve\n",
    "    expr=None,  # Optional filter expression\n",
    "    output_fields=[\"id\", \"embedding\", \"text_chunk\"]\n",
    ")\n",
    "\n",
    "# Combine the retrieved text chunks into a single context\n",
    "retrieved_text = \"\\n\\n\".join([result.text_chunk for result in results[0]])\n",
    "\n",
    "print(\"Retrieved Text Chunks for Context:\")\n",
    "print(retrieved_text)\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "08a469b5-e0d3-4e7b-a2ee-a9a586be8a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# genai.configure(api_key='Enter you palm api key here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "24fa1199-3f28-41af-bce0-db703b7c5532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What works has he done? \n",
      "\n",
      "Human-like Answer:\n",
      "- developed a web application that is capable of answering queries about his projects and work experience. This application allows HR and recruiters to interactively explore his resume, enhancing user engagement and usability.\n",
      "- developed three full-stack applications using React, Node.js, and MongoDB, which were hosted on AWS, improving user experience and functionality.\n",
      "- trained AI/ML models to classify images and generate text.\n",
      "- worked on a project to develop an image steganography technique that was recognized at an IEEE conference.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as palm\n",
    "\n",
    "# Set your PaLM API key\n",
    "palm.configure(api_key='Enter you palm api key ')\n",
    "\n",
    "# Function to generate a response using PaLM\n",
    "def generate_palm_response(chunks, query):\n",
    "    prompt = f\"Here are some relevant text chunks:\\n\\n{chunks}\\n\\nBased on the information in these chunks, can you tell me:\\n{query}\\n\\nAnswer:\"\n",
    "\n",
    "    response = palm.generate_text(\n",
    "        model='models/text-bison-001',\n",
    "        prompt=prompt,\n",
    "        candidate_count=1,  # Number of responses to generate\n",
    "        temperature=0.7,  # Adjust temperature for response variation\n",
    "        max_output_tokens=800  # Maximum tokens in the response\n",
    "    )\n",
    "\n",
    "    return response.result\n",
    "\n",
    "# Generate the response using PaLM\n",
    "human_like_answer = generate_palm_response(retrieved_text, query_text)\n",
    "print(query_text,\"\\n\")\n",
    "print(\"Human-like Answer:\")\n",
    "print(human_like_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cac35f0-1ed1-4f70-8fbc-1bd72bf4f35c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "2ff93707-6dc0-407d-ba33-be7fa7e95508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from pymilvus import connections, Collection\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import google.generativeai as palm\n",
    "\n",
    "# Set your PaLM API key here\n",
    "PALM_API_KEY = 'Enter you palm api key here'\n",
    "palm.configure(api_key=PALM_API_KEY)\n",
    "\n",
    "# Initialize the Milvus connection\n",
    "# connections.connect(alias=\"default\", host=\"127.0.0.1\", port=\"19530\")\n",
    "\n",
    "# Load the collection\n",
    "collection = Collection(name=\"resume_collection\")\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to generate embeddings\n",
    "def generate_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.detach().numpy().flatten()\n",
    "\n",
    "# Function to generate a response using PaLM\n",
    "def generate_palm_response(chunks, query):\n",
    "    prompt = f\"Here are some relevant text chunks related to your query:\\n\\n{chunks}\\n\\nBased on the information in these chunks, please answer the following query:\\n{query}\\n\\nAnswer:\"\n",
    "    response = palm.generate_text(\n",
    "        model='models/text-bison-001',\n",
    "        prompt=prompt,\n",
    "        candidate_count=1,  # Number of responses to generate\n",
    "        temperature=0.7,  # Adjust temperature for response variation\n",
    "        max_output_tokens=800  # Maximum tokens in the response\n",
    "    )\n",
    "    return response.result\n",
    "\n",
    "# Streamlit app\n",
    "st.title(\"PaLM and Milvus Integration Demo\")\n",
    "\n",
    "query_text = st.text_input(\"Enter your query text:\", \"\")\n",
    "\n",
    "if st.button(\"Search and Generate Response\"):\n",
    "    if query_text:\n",
    "        # Generate embedding for the query text\n",
    "        query_embedding = generate_embedding(query_text).tolist()\n",
    "\n",
    "        # Perform a similarity search\n",
    "        search_params = {\n",
    "            \"metric_type\": \"L2\",\n",
    "            \"params\": {\"nprobe\": 10},\n",
    "        }\n",
    "\n",
    "        results = collection.search(\n",
    "            data=[query_embedding],  # List of query embeddings\n",
    "            anns_field=\"embedding\",  # Field name of the embeddings\n",
    "            param=search_params,\n",
    "            limit=10,  # Number of similar entries to retrieve\n",
    "            expr=None,  # Optional filter expression\n",
    "            output_fields=[\"id\", \"embedding\", \"text_chunk\"]\n",
    "        )\n",
    "\n",
    "        # Combine the retrieved text chunks into a single context\n",
    "        retrieved_text = \"\\n\\n\".join([result.text_chunk for result in results[0]])\n",
    "\n",
    "        st.write(\"Retrieved Text Chunks for Context:\")\n",
    "        st.write(retrieved_text)\n",
    "\n",
    "        # Generate the response using PaLM\n",
    "        human_like_answer = generate_palm_response(retrieved_text, query_text)\n",
    "\n",
    "        st.write(\"Human-like Answer:\")\n",
    "        st.write(human_like_answer)\n",
    "    else:\n",
    "        st.write(\"Please enter a query text.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "db58724c-41d7-40e6-9c05-b75cd0d4feff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\pacecom_ptpl_d027\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (8.1.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\pacecom_ptpl_d027\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\pacecom_ptpl_d027\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipywidgets) (8.26.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\pacecom_ptpl_d027\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.11 in c:\\users\\pacecom_ptpl_d027\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipywidgets) (4.0.11)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in c:\\users\\pacecom_ptpl_d027\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipywidgets) (3.0.11)\n",
      "Requirement already satisfied: decorator in c:\\users\\pacecom_ptpl_d027\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\pacecom_ptpl_d027\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\pacecom_ptpl_d027\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\pacecom_ptpl_d027\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\pacecom_ptpl_d027\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\pacecom_ptpl_d027\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\pacecom_ptpl_d027\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\pacecom_ptpl_d027\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\pacecom_ptpl_d027\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\pacecom_ptpl_d027\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\pacecom_ptpl_d027\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\pacecom_ptpl_d027\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\pacecom_ptpl_d027\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6f3d04-6070-433a-8ab2-3a484d9d48dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
